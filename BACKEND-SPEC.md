Backend Implementation Guide: IMAP CampaignWizard1. Architectural Foundations and System Overview1.1. IntroductionThe IMAP CampaignWizard represents a critical evolution in internal advertising technology, designed to orchestrate high-volume Google Ads management workflows with precision and reliability. This document serves as the definitive backend implementation guide, establishing the architectural standards, data patterns, and service logic required to deliver an enterprise-grade application. The system is engineered to bridge the gap between the stateless, request-response nature of modern web applications and the complex, stateful, and often latent behavior of the Google Ads API.The selection of the technology stack—Litestar, ArangoDB, msgspec, and Arq—is not merely a collection of tools but a strategic alignment of capabilities designed to address specific bottlenecks inherent in AdTech platforms. The Google Ads API is characterized by deeply nested data structures, strict rate limiting, and complex policy enforcement logic.1 Consequently, the backend must prioritize serialization speed, flexible data modeling, and robust background processing over traditional CRUD simplicity.1.2. Technology Stack Justification & IntegrationThe architecture is built upon four primary pillars, each chosen to solve a specific dimension of the CampaignWizard's operational requirements.1.2.1. Litestar: The ASGI FrameworkLitestar is selected over comparable frameworks like FastAPI due to its superior performance characteristics and architectural rigor. In the context of CampaignWizard, where payload sizes for campaign synchronization can reach tens of megabytes, Litestar’s native support for strictly typed data injection and its highly optimized routing engine provide a necessary throughput advantage.Dependency Injection: Litestar’s hierarchical dependency injection system allows for the seamless provisioning of GoogleAdsClient instances and ArangoDB connections scoped to the request lifecycle. This ensures that authentication contexts are isolated and resources are managed efficiently.3Msgspec Integration: Litestar’s first-class support for msgspec aligns with our requirement for high-performance serialization, allowing the application to decode massive Google Ads JSON payloads directly into structured objects with minimal overhead.1.2.2. ArangoDB: The Multi-Model Persistence LayerThe complexity of Google Ads entities—where a Customer contains Campaigns, which contain AdGroups, which contain Ads, which link to Assets—forms a natural graph. However, the associated performance data (clicks, impressions, cost) is tabular and time-series in nature. ArangoDB’s multi-model capability allows us to model the structural hierarchy as a property graph while managing performance statistics in document collections optimized for aggregation.5Graph Traversals: AQL (ArangoDB Query Language) enables efficient retrieval of deep hierarchies (e.g., "fetch all assets for all ads in active campaigns") in a single network round-trip, a query pattern that would require recursive joins in a relational database.7Upsert Capabilities: The UPSERT operation in AQL is fundamental to our synchronization strategy, allowing for atomic "check-and-update" logic that preserves local user overrides while syncing remote data.81.2.3. Msgspec: High-Performance SerializationThe Google Ads API utilizes Protocol Buffers (protobuf) for transport, but the Python client library often interacts with these as dictionaries or JSON-compatible objects. msgspec provides a validation and serialization layer that is significantly faster than Pydantic or the standard json module. This speed is critical when processing the search_term_view reports, which can contain hundreds of thousands of rows per account.91.2.4. Arq: Asynchronous OrchestrationGiven the latency of the Google Ads API (where batch mutations can take several seconds and reporting jobs minutes), synchronous HTTP processing is non-viable. Arq, a lightweight job queue built on Redis, provides the necessary asynchronous execution environment. Unlike heavier alternatives like Celery, Arq’s integration with asyncio allows our worker nodes to handle I/O-bound tasks concurrently, maximizing the utility of the single-threaded Python runtime during network waits.102. Google Ads Authentication & Security ArchitectureThe security of the IMAP CampaignWizard relies fundamentally on the robust implementation of the OAuth2 protocol. Unlike a standard consumer application where a user's session is transient, this tool requires offline access to manage ad accounts autonomously via background workers. This requirement introduces specific security challenges regarding the storage and lifecycle management of the Refresh Token, the high-privilege credential that grants perpetual access to the user's Google Ads data.2.1. OAuth2 Web Application Flow DesignThe application must implement the Web Server Application Flow as defined by Google's identity protocols. This flow is distinct from the Service Account flow, which is generally inapplicable for managing standard third-party Google Ads accounts unless specific Domain-Wide Delegation is configured (which is rare in this context).12.1.1. The Authorization Request StrategyTo obtain a Refresh Token, the initial authorization request must be constructed with precision. If the request is malformed or missing specific parameters, Google will issue a short-lived Access Token but withhold the Refresh Token, rendering the background workers useless.The Litestar AuthController must construct a redirect URL containing the following critical parameters:client_id: The unique identifier for the CampaignWizard application in the Google Cloud Console.redirect_uri: The whitelisted callback endpoint (e.g., https://imap-wizard.internal/auth/callback).scope: This must explicitly include https://www.googleapis.com/auth/adwords to grant access to the Ads API.access_type: This MUST be set to offline. This parameter is the trigger for Google to generate a Refresh Token.1prompt: This should be set to consent. This forces the user to see the consent screen even if they have previously authorized the app. This is a critical redundancy; without it, if a user re-authenticates to fix a connection issue, Google might return only an Access Token, failing to rotate the Refresh Token.12Implementation Logic:The backend does not simply return a string; it should redirect the user agent. The state parameter must be used to prevent Cross-Site Request Forgery (CSRF). A random nonce should be generated, stored in a short-lived HttpOnly cookie or Redis key (bound to the user's session), and appended to the authorization URL.2.1.2. The Callback Handler & Token ExchangeUpon successful authorization, Google redirects the user back to the application with an authorization code. This code is a one-time-use credential that must be exchanged for the token pair.Security Constraint: This exchange must occur strictly server-side. The client_secret acts as the application's password and must never be exposed to the client browser or included in frontend JavaScript bundles.13The Exchange Process:State Validation: The handler first verifies that the state parameter returned by Google matches the nonce stored in the user's session. A mismatch indicates a potential CSRF attack, and the flow must be aborted immediately.Token Request: The backend sends a direct POST request to https://oauth2.googleapis.com/token containing the code, client_id, client_secret, and redirect_uri.Response Parsing: The response will contain the access_token (valid for 1 hour) and best critically, the refresh_token (valid indefinitely, with caveats).Token Verification: Best practice dictates calling the token info endpoint (https://oauth2.googleapis.com/tokeninfo) to verify the token's aud (audience) claim matches the application's Client ID, mitigating "confused deputy" attacks.2.2. Secure Refresh Token StorageThe refresh_token effectively provides complete control over the user's advertising spend. Storing this token in plain text is a "critical" severity vulnerability. If the database were compromised, an attacker could drain ad budgets across all managed accounts. Therefore, we must implement an Envelope Encryption strategy.132.2.1. Cryptographic ArchitectureWe will utilize AES-256-GCM (Galois/Counter Mode) for token encryption. GCM is an authenticated encryption mode, meaning it provides both confidentiality (keeping the token secret) and integrity (ensuring the token hasn't been tampered with).Key Hierarchy:Master Key (KEK - Key Encryption Key): This key is never stored in the database. It is injected into the application environment at runtime via a secrets manager (e.g., AWS Secrets Manager, HashiCorp Vault) or a secure environment variable (APP_MASTER_KEY).Data Encryption Key (DEK): Ideally, we generate a unique encryption key per tenant or user, encrypt the DEK with the KEK, and store the wrapped DEK alongside the data. For simplicity in this internal tool, we may use the KEK directly to encrypt the tokens, provided the KEK is rotated periodically.2.2.2. Storage Schema (UserCredentials Collection)In ArangoDB, credentials should be stored in a dedicated document collection, separate from the ad data, to allow for stricter access controls.Table 1: UserCredentials SchemaFieldTypeDescription_keyStringThe internal User ID (e.g., UUID).google_account_idStringThe numeric ID of the connected Google Ads manager account.encrypted_refresh_tokenString (Base64)The ciphertext of the refresh token.ivString (Base64)The Initialization Vector used for AES-GCM (must be unique per write).auth_tagString (Base64)The GCM authentication tag for integrity verification.key_versionIntegerIdentifier for the key used, facilitating future key rotation.statusEnumACTIVE, REVOKED, NEEDS_REAUTH.updated_atTimestampTime of last token update.Retrieval Logic for Arq Workers:When an Arq worker initializes a job:It retrieves the credential document for the target user.It accesses the APP_MASTER_KEY from the environment.It performs the AES-256-GCM decryption using the iv, auth_tag, and encrypted_refresh_token.If decryption fails (e.g., tag mismatch), it raises a security alert, as this implies database tampering.It initializes the GoogleAdsClient with the plaintext refresh token.2.3. Token Lifecycle & Rotation StrategyWhile the Refresh Token is long-lived, the Access Token is short-lived (1 hour). The google-ads Python library handles the automatic refreshing of the Access Token if the Refresh Token is valid. However, the system must handle the expiration or revocation of the Refresh Token itself.2.3.1. Handling invalid_grant ErrorsA Refresh Token may become invalid if:The user changes their Google account password.The user revokes the application's access in their Google Account security settings.The token has not been used for six months.The limit of 50 refresh tokens per user/client pair is exceeded (the oldest is revoked).Detection & Remediation Workflow:Monitor: The Arq worker must wrap all API initialization logic in a specific try/except block catching GoogleAdsException.Identify: Check if the error code is invalid_grant or not_authorized.Flag: Update the UserCredentials document status to NEEDS_REAUTH.Notify: Trigger an internal alert (email or Slack webhook) informing the user that their integration has paused and requires re-authentication.Circuit Break: Prevent further jobs for this user from running until the status is reset to ACTIVE via the OAuth2 callback flow.153. Data Modeling: ArangoDB Graph & Msgspec StructsThe data model is the skeleton of the application. Google Ads data is inherently hierarchical but also relational and distinct from the performance metrics it generates. A pure graph model is excellent for structure, but a hybrid approach is required for performance stats.3.1. Graph Schema Design (AdsGraph)ArangoDB allows us to define a named graph, AdsGraph, which enforces the structural integrity of the relationships between entities. We define Vertex Collections for the entities and Edge Collections for the relationships.53.1.1. Vertex Definitions1. CustomersRepresents the Google Ads account.Key: customer_id (e.g., 123-456-7890).Properties: descriptive_name, currency_code, time_zone, tracking_url_template.2. CampaignsThe top-level management unit.Key: campaign_id.Properties: name, status (ENABLED/PAUSED/REMOVED), advertising_channel_type (SEARCH, DISPLAY, PERFORMANCE_MAX), start_date, end_date, budget_id.Local Properties: sync_status, internal_label, draft_json (if representing a draft).3. AdGroupsContainers for ads and keywords.Key: ad_group_id.Properties: name, status, type, cpc_bid_micros.4. AdsThe creative units. Since Responsive Search Ads (RSAs) are now the standard, the Ad vertex essentially acts as a container for assets.Key: ad_id.Properties: final_urls, path1, path2, type (RESPONSIVE_SEARCH_AD).5. AssetsThe atomic creative elements (Headlines, Descriptions, Images, Videos).Key: asset_id.Properties: type (TEXT, IMAGE), asset_text, image_data (url, file_size).Modeling Note: Assets are reusable. A single "Free Shipping" headline asset is linked to thousands of Ads. This reuse is a primary driver for using a Graph DB; we store the Asset once and create thousands of edges.166. KeywordsTargeting criteria.Key: criterion_id.Properties: text, match_type (EXACT, PHRASE, BROAD), status.3.1.2. Edge Definitions & RelationshipsEdges in ArangoDB are documents themselves and can store properties. This feature is crucial for modeling Ad-Asset relationships.Table 2: Edge CollectionsEdge CollectionFromToProperties Stored on Edgeaccount_campaignCustomersCampaignscreated_atcampaign_adgroupCampaignsAdGroupscreated_atadgroup_adAdGroupsAdsstatus (AdGroupAd status)adgroup_keywordAdGroupsKeywordsstatus, cpc_bid_micros (Override)ad_assetAdsAssetsfield_type (HEADLINE/DESCRIPTION), pinned_field (HEADLINE_1), performance_labelInsight: The ad_asset EdgeThe relationship between an Ad and an Asset carries critical context. An asset is just text. The edge defines that "This text is used as a Headline and is Pinned to position 1" in this specific Ad. This is why ArangoDB is superior to a relational join table here; the edge is a first-class citizen.163.2. Msgspec Struct ImplementationTo ensure type safety and high-performance serialization, we define msgspec.Struct definitions that mirror the ArangoDB schema. These structs serve as the validation layer for data entering the system from the Google Ads API and data leaving via the internal REST API.Pythonimport msgspec
from typing import Optional, List
from enum import Enum

# Define Enums for strict typing
class EntityStatus(str, Enum):
    ENABLED = "ENABLED"
    PAUSED = "PAUSED"
    REMOVED = "REMOVED"
    UNKNOWN = "UNKNOWN"

class AdType(str, Enum):
    RESPONSIVE_SEARCH_AD = "RESPONSIVE_SEARCH_AD"
    EXPANDED_TEXT_AD = "EXPANDED_TEXT_AD"  # Legacy

# Base Struct for ArangoDB Documents
class ArangoDocument(msgspec.Struct):
    _key: str
    _id: Optional[str] = None
    _rev: Optional[str] = None

# Campaign Model
class Campaign(ArangoDocument):
    customer_id: str
    name: str
    status: EntityStatus
    advertising_channel_type: str
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    # Local Application Fields
    sync_status: str = "synced"
    is_dirty: bool = False
    internal_notes: Optional[str] = None

# Asset Link (Edge Representation)
class AdAssetLink(msgspec.Struct):
    asset_text: str  # Denormalized for frontend convenience
    asset_id: str
    field_type: str  # HEADLINE, DESCRIPTION
    pinned_field: Optional[str] = None
    performance_label: Optional[str] = None

# Ad Model with nested Assets (for API responses)
class AdResponse(ArangoDocument):
    ad_group_id: str
    final_urls: List[str]
    type: AdType
    headlines: List[AdAssetLink]
    descriptions: List[AdAssetLink]
3.3. Stats Storage Strategy: The "Vertex-Centric Index"The Challenge: Storing time-series performance data (Impressions, Clicks, Cost) directly on the Graph vertices leads to "write amplification" and massive document growth. Storing it as a linked list of edges is inefficient for aggregation.The Solution: Use a separate Document Collection named DailyStats.Schema for DailyStats:_key: A deterministic hash of entity_id + date + device + network.entity_id: The _id of the parent object (e.g., Campaigns/123).date: ISO Date string (YYYY-MM-DD).metrics: Nested object { impressions: int, clicks: int, cost_micros: int, conversions: float }.segments: Nested object { device: str, network: str }.Performance Optimization:We utilize ArangoDB's Persistent Index on ["entity_id", "date"]. This creates a sorted index that allows for extremely fast range scans.Query: "Get total cost for Campaign X in January."AQL:Code-SnippetFOR s IN DailyStats
  FILTER s.entity_id == "Campaigns/X"
  FILTER s.date >= "2024-01-01" AND s.date <= "2024-01-31"
  COLLECT AGGREGATE total_cost = SUM(s.metrics.cost_micros)
  RETURN total_cost
This approach decouples the "Structure" (Graph) from the "Performance" (Stats), allowing us to drop old stats data purely by date without affecting the graph topology.174. Reporting Engine: GAQL & Synchronization LogicThe Reporting Engine is the bidirectional heart of the system. It pulls data from Google (Ingestion) and presents it to the user. The critical challenge is merging the remote "source of truth" with local "user intent" without data loss.4.1. GAQL Query EngineeringThe Google Ads Query Language (GAQL) allows for SQL-like selection of resources. We must construct queries that balance granularity with payload size.4.1.1. The Search Term View QueryThe search_term_view report is the most data-intensive. It tells us what queries actually triggered the ads.Query Design:SQLSELECT
  search_term_view.search_term,
  search_term_view.status,
  segments.keyword.info.text,
  metrics.clicks,
  metrics.impressions,
  metrics.cost_micros,
  metrics.conversions
FROM search_term_view
WHERE segments.date DURING LAST_30_DAYS
  AND metrics.impressions > 0
Handling the search_term_view.status Field:This field is critical for workflow logic.18ADDED: The search term already exists as a targeted keyword in the ad group.Action: Display as "Existing".EXCLUDED: The search term matches a negative keyword.Action: Display as "Blocked".NONE: The search term is NOT explicitly targeted (it matched via Broad or Phrase match).Action: This is the actionable insight. The user should be presented with options to "Add as Keyword" or "Add as Negative".4.1.2. Segmentation ComplexityAdding segments like segments.device or segments.date multiplies the number of rows returned.Strategy: For the DailyStats collection, we ingest with segments.date. For the Graph structure (Campaign settings), we query without segments to get the singular current state of the entity.4.2. AQL Upsert Logic: The "Merge" PatternWhen syncing a Campaign from Google, we simply cannot overwrite the local document. The local document might contain:Local Metadata: Tags, notes, workflow states.Draft Changes: A user might have renamed the campaign locally (is_dirty=True) but hasn't pushed to Google yet. If we overwrite with Google's data, we revert their work.The Solution: AQL UPSERT with Conditional MERGEWe use the OLD pseudo-variable in AQL to access the document state before the update.The Master AQL Query:Code-SnippetFOR doc IN @batch
  UPSERT { _key: doc._key }
  INSERT MERGE(doc, {
      first_synced_at: DATE_NOW(),
      local_status: "clean"
  })
  UPDATE MERGE(doc, {
      last_synced_at: DATE_NOW(),
      // CONDITIONAL LOGIC STARTS HERE
      // 1. Preserve local metadata fields that Google doesn't know about
      internal_notes: OLD.internal_notes,
      internal_tags: OLD.internal_tags,

      // 2. Protect Dirty Fields
      // If the local name is dirty, keep the OLD name, ignore the NEW (Google) name
      name: OLD.is_dirty? OLD.name : doc.name,
      status: OLD.is_dirty? OLD.status : doc.status,

      // 3. Always update stats/read-only fields
      serving_status: doc.serving_status
  })
  IN Campaigns
Mechanism Explained:UPSERT: Atomically checks if _key exists.INSERT: Executed if the document is new. We initialize local fields.UPDATE: Executed if the document exists.OLD.is_dirty: This check is vital. It implements a "Local Wins" policy for unpushed changes. If the user changed the name, is_dirty is true. The sync logic sees this and refuses to overwrite the name with the (stale) value from Google, ensuring the user's draft persists until they choose to push it.85. Campaign Creation Service: Mutate Operations & Policy LogicCreating and updating entities involves the GoogleAdsService.mutate method. This is a transactional endpoint: either the entire batch succeeds, or it fails (unless partial_failure is used).5.1. Handling Temporary IDsWhen creating a new Campaign structure (Campaign + AdGroup + Ad) in a single request, the entities do not yet have IDs. We cannot link the AdGroup to the Campaign using a real ID.The Temporary ID Pattern:Google allows the use of negative integers (-1, -2, ...) as temporary resource names within a single batch.Implementation Steps:Allocate IDs: The service assigns temp_id=-1 to the Campaign.Reference in Parent: When creating the AdGroup operation, we set the campaign field to customers/{cid}/campaigns/-1.Reference in Child: When creating the Ad operation, we set ad_group to customers/{cid}/adGroups/-2.Submission: We send all operations in a single mutate_operations list. Google resolves the DAG (Directed Acyclic Graph), creates the Campaign first, gets its real ID, and uses that for the AdGroup creation.215.2. Policy Violation Error Handling (Recursive Exemptions)Google Ads performs real-time policy checks. If an ad contains restricted content (e.g., medical terms, trademarks), the API throws a GoogleAdsException with a PolicyViolationError.Many violations are Exemptible. This means the user can acknowledge the policy (e.g., "I have a certificate to advertise Botox") and resubmit.The Recursive "Try-Catch-Exempt" Loop:Initial Attempt: Submit the mutation batch.Exception Catching: Catch GoogleAdsException.Analysis: Iterate through failure.errors. Check if error_code is POLICY_VIOLATION.Exemptibility Check: Check error.details.policy_violation_details.is_exemptible.If False: The error is fatal (e.g., profanity). Abort and report to user.If True: Extract the policy_violation_key.Payload Modification:Locate the specific operation that failed (using field_path_elements).Inject the policy_violation_key into the policy_validation_parameter.ignorable_policy_topics list of that operation.Retry: Recursively call the mutate function with the modified operations.Safety Limit: Implement a max_retries counter (e.g., 3) to prevent infinite loops if the API behaves inconsistently.22Code Structure (Python Pseudocode):Pythonasync def execute_mutation(client, customer_id, operations, attempt=1):
    try:
        return client.service.google_ads.mutate(customer_id=customer_id, mutate_operations=operations)
    except GoogleAdsException as ex:
        if attempt > 3: raise ex
        
        # Analyze for Exemptions
        exemptions_found = False
        for error in ex.failure.errors:
            if is_exemptible_policy_error(error):
                key = error.details.policy_violation_details.key
                # Find the operation index and inject the key
                op_index = error.location.field_path_elements.index
                add_exemption_to_op(operations[op_index], key)
                exemptions_found = True
        
        if exemptions_found:
            return await execute_mutation(client, customer_id, operations, attempt + 1)
        raise ex
5.3. Managing Draft State in ArangoDBBefore a campaign is pushed to Google, it exists as a "Draft".Draft Storage: We store drafts in the same Campaigns collection but with status='DRAFT' and is_draft=True.Validation: Msgspec allows us to define a DraftCampaign struct with looser validation (optional fields) compared to the LiveCampaign struct.Promotion: When "Push" is clicked:The DraftCampaign is validated against the stricter LiveCampaign schema.If valid, it enters the Mutate/Temporary ID pipeline.On success, the response returns the real campaign_id.We perform a "Swap" in ArangoDB: Delete the Draft vertex and replace it with the new Live vertex (or update the keys/IDs of the existing vertex), ensuring the sync_status is updated to synced.6. Background Processing & Resilience with ArqGiven the strict rate limits and network instability inherent in external API integrations, the background worker system must be resilient.6.1. Arq Worker Integration with LitestarArq runs as a separate process from the Litestar web server. It does not automatically share the Litestar Dependency graph.Integration Pattern:We define a WorkerSettings class that utilizes the on_startup hook to initialize resources manually.Python# worker.py
async def startup(ctx):
    # Manually initialize clients for the worker context
    ctx['arango'] = await create_arango_client()
    ctx['secrets'] = await SecretManager()
    ctx['http_client'] = httpx.AsyncClient()

class WorkerSettings:
    functions = [sync_account_task, push_mutations_task]
    on_startup = startup
    redis_settings = RedisSettings(host='redis', port=6379)
6.2. Rate Limiting & Circuit BreakersGoogle Ads API has a limit of 15,000 operations per day for Basic Access.Implementation:Header Inspection: The worker must inspect the Retry-After header on 429 responses.Global Lock: If a rate limit is hit, the worker should set a Redis key rate_limit_lock:{customer_id} with a TTL equal to the retry duration.Job Guard: At the start of every job, check for this lock. If present, reschedule the job (self.retry_in(ttl)).6.3. Partial Failures in Batch ProcessingWhen syncing 10,000 keywords, one might fail.Request: Set partial_failure=True in the API request.Response Handling: The response will be HTTP 200, but will contain a partial_failure_error field.Logic: The worker must parse this error field to identify which specific operations failed. It should mark those specific entities as SYNC_ERROR in ArangoDB while letting the successful ones commit. This prevents a single malformed keyword from blocking the synchronization of an entire account.247. Operational Requirements & Conclusion7.1. ObservabilityStructured Logging: All logs must be JSON formatted and include trace_id, customer_id, and worker_id.Metrics: Monitor google_ads_api_latency and arq_job_failure_rate. A spike in failure rate usually indicates a Google API outage or a policy change.7.2. ConclusionThis architecture provides a comprehensive blueprint for the IMAP CampaignWizard. By strictly adhering to the Graph-for-Structure, Document-for-Stats model in ArangoDB, utilizing Litestar and msgspec for high-throughput I/O, and implementing the rigorous OAuth2 and Mutate patterns described, the system effectively mitigates the risks associated with building on top of the complex Google Ads API. The design ensures data integrity via the Upsert-Merge pattern, security via Envelope Encryption, and operational resilience via Arq's asynchronous orchestration.